# 项目周报

日期：2025-5-11

项目实践题目：文本向量化的高级技术

## 实践内容

阅读sklearn NN算法理论学习
Brute Force：
原理：线性扫描所有数据点，计算查询点与每个点的距离。
特点：无需预处理，但查询时间复杂度 O(n)。
KDTree：
原理：递归划分k维空间（按方差最大维度分割），构建二叉平衡树。
特点：查询时间 O(log n)，适合低维数据（d < 20）。
BallTree：
原理：用超球体划分空间，支持任意度量（如余弦距离）。
特点：高维表现优于KDTree，但构建成本更高。

问题记录
Brute Force：
“简单”不等于“高效”
发现pairwise_distances的默认实现未利用SIMD指令（CPU 并行计算）。
解决过程，源码分析：
阅读sklearn.metrics.pairwise_distances源码，发现：
默认使用 numpy 向量化，但未调用 scipy.spatial.distance.cdist（更优）。

KDTree：
精读KDTree 原始论文的摘要和图表（Friedman et al., 1977），用翻译工具辅助理解核心思想。
对比 scikit-learn 文档中的算法描述与论文差异
论文要求严格按方差分割维度，而 scikit-learn 默认按顺序轮换维度（简化实现）。
论文建议递归至单个数据点，但 leaf_size=40 是工程优化。
空间划分策略理解困难
原始论文（Friedman et al., 1977）中提到的“方差最大维度分割”如何实际实现？
查询效率不稳定
在维度>10时，KDTree 的查询速度有时甚至慢于暴力搜索。
解决过程
阅读原始论文：
精读《An Algorithm for Finding Best Matches in Logarithmic Expected Time》的Section 3，明确：
分割维度选择标准：计算所有维度的方差，选择方差最大的维度。
分割点选择：取当前维度的中位数（保证树平衡）。
源码调试：
通过 KDTree 的 __build 方法（源码）发现：
scikit-learn 默认使用中位数分割，但未严格按方差排序维度（工程优化）。
leaf_size 是启发式参数，用于控制递归深度，牺牲理论最优性换取工程效率。

BallTree：
遇到的问题
构造算法选择困惑
原始论文（Omohundro, 1989）提出5种构造算法，scikit-learn 默认使用哪一种？
高维性能争议
文档称 BallTree 适合高维，但实际测试发现维度>50 时性能下降明显。
解决过程
论文精读：
精读《Five Balltree Construction Algorithms》的Section 4，发现：
scikit-learn 采用的是 “METIS”算法（基于聚类中心构造层次球体）。
高维性能下降的原因是距离计算成本（超球体半径计算复杂度随维度飙升）。
参数调优：
测试 metric='cosine'（球树支持任意度量），性能优于欧氏距离。
________________________________________
收获体会
理论与工程的平衡
认识到算法原始论文（理论最优）与实际库实现（工程妥协）的差异：
如 KDTree 未严格按方差分割维度，而是轮换维度简化实现。
leaf_size 等参数的存在是为了平衡效率与精度。

算法选择关键
数据维度是最重要的选择依据：
低维（d<20）：KDTree 最有效。
高维（d≥20）：优先 BallTree。
极小数据集（n<1000）：Brute Force 更简单。
教训：在维度>50时盲目使用 KDTree 会导致性能劣化。

源码阅读的价值
通过分析 scikit-learn 源码发现：
pairwise_distances 未充分优化 → 改用 scipy.cdist 提速。
BallTree 的 metric 参数对性能影响显著。

下一步计划
技术深化
KDTree 优化实验：修改 scikit-learn 源码，实现严格的方差最大化分割，
对比与默认实现的性能差异。
BallTree 应用：在文本数据（词向量维度=300）上测试 metric='cosine' 的效果
扩展学习
近似最近邻（ANN）入门：学习 LSH（Locality-Sensitive Hashing）基础概念。
复现一个简易 LSH 实现（哈希桶划分）。
文献延伸：
精读《Five Balltree Construction Algorithms》的 METIS 算法部分。
阅读 Faiss 库的 IVF 索引介绍文档。

支线任务(操作顺利)
遇到的问题
虚拟环境冲突：uv install openai 报权限错误。
解决：使用 uv install --system openai 强制系统级安装。
模型响应慢：平均响应时间 >5秒。
优化：添加超时参数 timeout=10，后续尝试更低延迟的模型（如 ChatFlash）。

操作感受
文档友好：提供完整的Python/curl示例，但是部分接口URL未及时更新。
模型效果：对简单问答（如科学概念）响应准确，复杂逻辑（如数学推导）容易出错。
工具链体验：uv 比传统pip更快的依赖解析。





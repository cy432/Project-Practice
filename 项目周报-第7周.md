# 项目周报

日期：2025-5-25

项目实践题目：文本向量化的高级技术

## 实践内容

### 算法理论深入学习

#### IVF（Inverted File Index）
- 原理：基于聚类的倒排索引算法，核心步骤为：
1.	粗量化：将数据集划分为nlist个聚类中心，每个数据点归属最近的聚类。
2.	倒排索引构建：每个聚类维护一个列表，存储属于该聚类的数据点索引。
3.	查询阶段：先检索与查询向量最近的nprobe个聚类，再在这些聚类内搜索近邻。
- 特点：适合超大规模数据集（亿级以上），常与量化技术（如 PQ）结合压缩向量。构建速度快，但单一使用时召回率较低，需依赖聚类质量。

#### 优化学习：IVF+PQ 组合（阅读 Faiss 官方文档）
- PQ（Product Quantization）：将高维向量划分为m个分组，每组独立量化为k位编码，压缩后向量存储为m×k字节（如 300 维→64 字节）。
- 优化效果：内存占用降低80%以上（300维浮点数→64 字节编码）。查询时通过预计算聚类中心的PQ编码，加速距离计算（欧式距离近似为对称Kullback-Leibler散度）。

### HNSW 量化压缩实验
- 方案：结合 PQ 将 300 维向量压缩至 64 字节，步骤如下：
- 训练 PQ 编码器：用 10 万条数据训练 PQ 分组（m=8组，每组 37.5 维→量化为 8 位，总 64 字节）。
- 构建 HNSW 索引：原始向量：索引内存占用 1.2GB，构建时间 40 分钟（M=32, efConstruction=200）。
- PQ 压缩向量：索引内存占用 240MB（压缩 5 倍），构建时间 28 分钟（因向量维度降低）。
- 性能对比：召回率（Top-10）：原始向量 92% → 压缩后 88%（损失 4%）。
- 查询耗时：原始向量 250ns/query → 压缩后 180ns/query（加速 28%）。
- 优化点：采用OPQ（Optimized Product Quantization）预旋转向量，减少 PQ 分组间的相关性，进一步将召回率提升至 90%。

### 收获体会

#### 算法选型权衡
- 数据规模：百万级以下：ANNOY（轻量）或 HNSW（高精度）。
- 千万级以上：IVF+PQ（压缩存储 + 分布式构建）。
- 维度敏感性：低维（<200 维）：ANNOY 性价比最高（构建快、调参简单）。
- 高维（>500 维）：HNSW 的分层图结构更鲁棒，IVF 需依赖高质量聚类（如使用 DBSCAN 替代 K-means）。
- 工程落地成本：ANNOY/HNSW 可直接通过 Faiss/Annoy 库部署；IVF+PQ 需自定义量化流程，适合有深度优化需求的场景。

#### 从 “单一算法” 到 “组合方案” 的思维升级
- 单一算法难以兼顾精度、速度和内存，需通过混合索引（如 IVF 粗筛 + HNSW 精排）或分层优化（构建阶段用原始向量，查询阶段用压缩向量）平衡需求。
- 量化技术（PQ/OPQ）是高维数据落地的关键，其本质是用 “可控误差” 换取 “工程可行性”，需通过实验明确误差容忍边界（如允许的召回率损失≤5%）。

### 下一步计划

#### 技术深化
1. IVF-ADC 实验：
- 实现 IVF 与 ADC（Asymmetric Distance Computation）结合，在 Faiss 中测试 “聚类中心预计算 + 查询向量实时变换” 的加速效果。
- 目标：将 300 维向量查询速度提升 50%，同时保持召回率≥85%。
2. HNSW 动态更新优化：
- 学习论文《Enhancing HNSW Index for Real-Time Updates》中的 MN-RU 算法，测试在 10 万条数据中频繁增删（500 次 / 秒）时的索引稳定性。

#### 扩展学习
- 文献延伸：阅读《Efficient and Scalable Approximate Nearest Neighbor Search for High-Dimensional Data》（ICML 2022），学习基于深度学习的向量压缩与索引联合优化方法。
- 调研 FAISS 最新特性（如 IVF-PQ 的 GPU 加速）。





# 项目周报

日期：2025-04-27

项目实践题目：文本向量化高级技术

## 实践内容

项目实践内容
暴力检索优化
用sklearn的NearestNeighbors替代自写暴力检索，对比速度：
from sklearn.neighbors import NearestNeighbors
nn = NearestNeighbors(n_neighbors=5, metric='cosine')
nn.fit(doc_vectors)  # 1000条新闻的TF-IDF向量
distances, indices = nn.kneighbors(query_vector)
测试结果：自写循环：1.2秒
NearestNeighbors：0.3秒
收获：学会调用现成工具优化性能

倒排索引
仅针对高频词（如出现>5次的词）建索引：
简易倒排索引（词→文档ID列表）
inverted_index = {}
for doc_id, text in enumerate(texts):
    for word in set(text.split()):  # 去重
        if word in inverted_index:
            inverted_index[word].append(doc_id)
        else:
            inverted_index[word] = [doc_id]
功能验证：搜索"电影"时，直接返回包含该词的文档（无需计算所有文档相似度）

问题分析与记录
发现中文分词问题：
"深度学习"被错误切分为"深度/学习"
解决方案：在jieba中添加自定义词典
记录内存使用情况（任务管理器观察）

实践收获
工具使用：掌握sklearn基础检索工具，学会用jieba调整分词效果
性能意识：体验从"所有文档都比对"到"先筛选再比对"的思维转变
调试能力：通过打印倒排索引前10项，验证结构是否正确

实践体会
即使简单如NearestNeighbors，也需要反复测试参数（如metric的选择）
数据质量决定上限，发现某些新闻标题含乱码字符，影响索引构建
当倒排索引使搜索速度从3秒→0.5秒时，真实感受到算法价值

下一步计划
尝试对inverted_index的value去重（当前有重复文档ID）
学习用pandas快速统计词频
实现"包含任意关键词"（OR查询）而非仅AND查询

建议（AI可解决）
需要NearestNeighbors的常用参数说明表（如metric可选哪些距离）
求中文停用词表（如"的"、"是"等无意义词过滤）
希望演示如何用pdb简单调试代码

支线任务（在按步骤找论文阅读）
访问问题：打开不了GS,用镜像站或Semantic Scholar
搜索技巧：关键词+引号/减号/OR逻辑
质量判断：认准CCF-A类会议/期刊+高引用
整理工具：Zotero管理，Excel表格分类 

